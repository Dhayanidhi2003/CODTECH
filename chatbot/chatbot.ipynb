{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oMK4-6tQ2X3C"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "chatbot_nlp.py\n",
        "\n",
        "A simple NLP-based chatbot using NLTK for preprocessing and scikit-learn\n",
        "for intent classification.\n",
        "\n",
        "Features:\n",
        "- Tokenization, stopword removal, lemmatization (NLTK)\n",
        "- TF-IDF vectorizer + LogisticRegression classifier\n",
        "- Simple rule-based fallback and response selection\n",
        "- Save / load trained model + vectorizer\n",
        "- Interactive CLI chat loop\n",
        "\n",
        "How to run:\n",
        "1. pip install nltk scikit-learn joblib\n",
        "2. python chatbot_nlp.py\n",
        "3. (First run will download small NLTK datasets)\n",
        "\n",
        "Extend:\n",
        "- Add more intents/responses in the INTENTS list\n",
        "- Replace classifier with neural models for more complex behavior\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "# NLP & ML libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Ensure necessary NLTK data is downloaded (only first run) --\n",
        "nltk_packages = [\"punkt\", \"wordnet\", \"omw-1.4\", \"stopwords\", \"punkt_tab\"]\n",
        "for pkg in nltk_packages:\n",
        "    try:\n",
        "        nltk.data.find(pkg)\n",
        "    except LookupError:\n",
        "        nltk.download(pkg)\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Example intents dataset\n",
        "# ------------------------------\n",
        "# This is a small sample. Add more examples to improve accuracy.\n",
        "INTENTS = [\n",
        "    {\n",
        "        \"tag\": \"greeting\",\n",
        "        \"patterns\": [\n",
        "            \"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\",\n",
        "            \"what's up\", \"yo\", \"howdy\", \"hiya\"\n",
        "        ],\n",
        "        \"responses\": [\n",
        "            \"Hello! How can I help you today?\",\n",
        "            \"Hi there â€” what can I do for you?\",\n",
        "            \"Hey! Need any help?\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"goodbye\",\n",
        "        \"patterns\": [\"bye\", \"goodbye\", \"see you\", \"see ya\", \"talk later\"],\n",
        "        \"responses\": [\"Goodbye! Have a great day.\", \"See you later!\", \"Bye â€” come back anytime!\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"thanks\",\n",
        "        \"patterns\": [\"thanks\", \"thank you\", \"much appreciated\", \"thx\"],\n",
        "        \"responses\": [\"You're welcome!\", \"No problem!\", \"Anytime ğŸ˜Š\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"about_bot\",\n",
        "        \"patterns\": [\"who are you\", \"what are you\", \"your name\", \"about you\"],\n",
        "        \"responses\": [\n",
        "            \"I'm a simple chatbot built with NLTK and scikit-learn.\",\n",
        "            \"I am an NLP chatbot created to demonstrate intent classification.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"help\",\n",
        "        \"patterns\": [\"I need help\", \"can you help me\", \"assist me\", \"i need assistance\"],\n",
        "        \"responses\": [\n",
        "            \"Sure â€” tell me what you need help with.\",\n",
        "            \"I'm here to help. What would you like to do?\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"weather_query\",\n",
        "        \"patterns\": [\n",
        "            \"what's the weather\", \"tell me the weather\", \"is it raining\",\n",
        "            \"how's the weather\", \"weather today\"\n",
        "        ],\n",
        "        \"responses\": [\n",
        "            \"I can't fetch live weather yet, but you can integrate a weather API such as OpenWeatherMap.\",\n",
        "            \"I don't have live weather access in this demo â€” add an API to enable that.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"time_query\",\n",
        "        \"patterns\": [\"what time is it\", \"tell me the time\", \"current time\", \"time now\"],\n",
        "        \"responses\": [\n",
        "            \"I can tell the local time if you add a timezone utility.\",\n",
        "            \"Time-check feature isn't enabled in this demo. Add Python's datetime to respond.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"smalltalk_name\",\n",
        "        \"patterns\": [\"what's your favorite color\", \"do you like music\", \"are you a human\"],\n",
        "        \"responses\": [\n",
        "            \"I don't have personal preferences, but I like helping you!\",\n",
        "            \"I'm not human â€” just code and models.\"\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSPOIzAi31rX",
        "outputId": "b46eee0d-0a31-4f3c-bcf8-8b1b710b4221"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 2) NLP Preprocessing helpers\n",
        "# ------------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean + normalize text:\n",
        "    - lowercase\n",
        "    - remove non-alphanumeric characters except spaces\n",
        "    - tokenize, remove stopwords, lemmatize\n",
        "    - join back into a string\n",
        "    This function will be used inside the TfidfVectorizer via a tokenizer wrapper.\n",
        "    \"\"\"\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove URLs and emails (simple)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|@\\S+\", \" \", text)\n",
        "\n",
        "    # remove punctuation (keep spaces & alphanumerics)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "\n",
        "    # tokenize using nltk\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # remove stopwords and lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(tok) for tok in tokens if tok not in STOPWORDS and tok.isalpha()]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "def simple_tokenizer(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Tokenizer wrapper expected by TfidfVectorizer: returns list of tokens\n",
        "    after normalization. scikit-learn expects a callable tokenizer that returns tokens.\n",
        "    \"\"\"\n",
        "    normalized = normalize_text(text)\n",
        "    return normalized.split()"
      ],
      "metadata": {
        "id": "lpJ6RJjM36me"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 3) Prepare dataset for training\n",
        "# ------------------------------\n",
        "def build_dataset(intents: List[Dict]) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Convert the INTENTS structure into X (text samples) and y (tags).\n",
        "    Each pattern becomes a training sample.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for intent in intents:\n",
        "        tag = intent[\"tag\"]\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            X.append(pattern)\n",
        "            y.append(tag)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "dwmadeEz3_er"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 4) Build & train a classifier pipeline\n",
        "# ------------------------------\n",
        "def build_pipeline() -> Pipeline:\n",
        "    \"\"\"\n",
        "    Build a scikit-learn Pipeline:\n",
        "    - TfidfVectorizer with the simple_tokenizer\n",
        "    - LogisticRegression classifier for multiclass intent classification\n",
        "    \"\"\"\n",
        "    tfidf = TfidfVectorizer(tokenizer=simple_tokenizer, ngram_range=(1, 2))\n",
        "    clf = LogisticRegression(max_iter=500)\n",
        "    pipeline = Pipeline([(\"tfidf\", tfidf), (\"clf\", clf)])\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def train_pipeline(pipeline: Pipeline, X: List[str], y: List[str]) -> Pipeline:\n",
        "    \"\"\"\n",
        "    Train the pipeline. Splits for a quick validation report.\n",
        "    Returns trained pipeline.\n",
        "    \"\"\"\n",
        "    if len(X) < 2:\n",
        "        raise ValueError(\"Need at least 2 training samples\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Quick evaluation\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(\"\\n--- Training evaluation (quick) ---\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return pipeline"
      ],
      "metadata": {
        "id": "WSklMhFs6bH3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LcIPUAaC6iU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 5) Response selection & chat logic\n",
        "# ------------------------------\n",
        "# Load a mapping of tag -> responses for quick lookup\n",
        "TAG_TO_RESPONSES = {intent[\"tag\"]: intent[\"responses\"] for intent in INTENTS}\n",
        "\n",
        "\n",
        "def get_response_for_tag(tag: str) -> str:\n",
        "    \"\"\"\n",
        "    Choose a random response from the list for the predicted tag.\n",
        "    \"\"\"\n",
        "    responses = TAG_TO_RESPONSES.get(tag, [])\n",
        "    if responses:\n",
        "        return random.choice(responses)\n",
        "    return \"Sorry, I don't have a response for that.\"\n",
        "\n",
        "\n",
        "def predict_intent(pipeline: Pipeline, message: str, threshold: float = 0.5) -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Predict intent tag for a given message.\n",
        "    - Returns (tag, probability)\n",
        "    - If highest probability < threshold, returns ('fallback', probability)\n",
        "    \"\"\"\n",
        "    # pipeline.predict_proba returns probabilities for classes\n",
        "    proba = pipeline.predict_proba([message])[0]  # shape = (n_classes, )\n",
        "    classes = pipeline.classes_\n",
        "    best_idx = proba.argmax()\n",
        "    best_tag = classes[best_idx]\n",
        "    best_prob = proba[best_idx]\n",
        "    if best_prob < threshold:\n",
        "        return \"fallback\", best_prob\n",
        "    return best_tag, best_prob\n",
        "\n",
        "\n",
        "def fallback_response() -> str:\n",
        "    \"\"\"\n",
        "    Generic fallback when model is not confident.\n",
        "    \"\"\"\n",
        "    return \"Sorry, I didn't understand that. Can you rephrase or ask something else?\""
      ],
      "metadata": {
        "id": "DIEaNKtH6esG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 6) Save / Load helpers\n",
        "# ------------------------------\n",
        "def save_model(pipeline: Pipeline, filepath: str):\n",
        "    joblib.dump(pipeline, filepath)\n",
        "    print(f\"Model saved to {filepath}\")\n",
        "\n",
        "\n",
        "def load_model(filepath: str) -> Pipeline:\n",
        "    if not os.path.exists(filepath):\n",
        "        raise FileNotFoundError(f\"No model found at {filepath}\")\n",
        "    print(f\"Loading model from {filepath}\")\n",
        "    return joblib.load(filepath)"
      ],
      "metadata": {
        "id": "YdDWhV_b6jbW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 7) Interactive chat loop\n",
        "# ------------------------------\n",
        "def chat_loop(pipeline: Pipeline):\n",
        "    \"\"\"\n",
        "    Simple CLI chat loop. Type 'quit' or 'exit' to end.\n",
        "    \"\"\"\n",
        "    print(\"Chatbot is ready! (type 'quit' or 'exit' to stop)\\n\")\n",
        "    while True:\n",
        "        message = input(\"You: \").strip()\n",
        "        if not message:\n",
        "            continue\n",
        "        if message.lower() in (\"quit\", \"exit\"):\n",
        "            print(\"Bot: Goodbye! ğŸ‘‹\")\n",
        "            break\n",
        "\n",
        "        # optional: handle simple rule-based patterns before ML (numbers, greetings, etc)\n",
        "        # but our classifier already covers greetings\n",
        "\n",
        "        tag, prob = predict_intent(pipeline, message, threshold=0.3)\n",
        "        if tag == \"fallback\":\n",
        "            print(f\"Bot: {fallback_response()} (confidence={prob:.2f})\")\n",
        "        else:\n",
        "            response = get_response_for_tag(tag)\n",
        "            print(f\"Bot: {response} (intent='{tag}', confidence={prob:.2f})\")"
      ],
      "metadata": {
        "id": "jTC3zcaN6mKj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 8) Main: train (or load) and run\n",
        "# ------------------------------\n",
        "MODEL_FILE = \"chatbot_pipeline.joblib\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Build dataset\n",
        "    X, y = build_dataset(INTENTS)\n",
        "\n",
        "    # If a saved model exists, load it; otherwise train a new one.\n",
        "    if os.path.exists(MODEL_FILE):\n",
        "        pipeline = load_model(MODEL_FILE)\n",
        "    else:\n",
        "        pipeline = build_pipeline()\n",
        "        pipeline = train_pipeline(pipeline, X, y)\n",
        "        save_model(pipeline, MODEL_FILE)\n",
        "\n",
        "    # Start interactive chat\n",
        "    chat_loop(pipeline)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLq_1bGz6pB4",
        "outputId": "a2bdaa70-55ce-43bc-cc50-d7bbbbee7086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from chatbot_pipeline.joblib\n",
            "Chatbot is ready! (type 'quit' or 'exit' to stop)\n",
            "\n",
            "You: Hi\n",
            "Bot: Sorry, I didn't understand that. Can you rephrase or ask something else? (confidence=0.24)\n",
            "You: hi\n",
            "Bot: Sorry, I didn't understand that. Can you rephrase or ask something else? (confidence=0.24)\n",
            "You: hello\n",
            "Bot: Hey! Need any help? (intent='greeting', confidence=0.39)\n",
            "You: who are you\n",
            "Bot: Sorry, I didn't understand that. Can you rephrase or ask something else? (confidence=0.24)\n",
            "You: who are you?\n",
            "Bot: Sorry, I didn't understand that. Can you rephrase or ask something else? (confidence=0.24)\n"
          ]
        }
      ]
    }
  ]
}